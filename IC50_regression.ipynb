  {
   "cell_type": "markdown",
   "id": "022458ed-b64b-4fe9-9b3b-a8d4a18978f9",
   "metadata": {},
   "source": [
    "Задача регрессии (для IC50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9feaa179-b5fd-432b-86fc-469b83dc88ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее R2: 0.19635426039008214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_linear = LinearRegression()\n",
    "\n",
    "model_linear.fit(X_train_ic, y_train_ic)\n",
    "pred_linear_ic = model_linear.predict(X_test_ic)\n",
    "\n",
    "scores_linear = cross_val_score(model_linear, X_train_ic, y_train_ic, cv=5, scoring='r2')\n",
    "print(\"Среднее R2:\", scores_linear.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7bfcb174-36c1-4d6e-8ad8-376e0dd0f92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее R2: 0.25778017944636966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_forest = RandomForestRegressor()\n",
    "\n",
    "model_forest.fit(X_train_ic, y_train_ic)\n",
    "pred_forest_ic = model_forest.predict(X_test_ic)\n",
    "scores_forest = cross_val_score(model_forest, X_train_ic, y_train_ic, cv=5, scoring='r2')\n",
    "print(\"Среднее R2:\", scores_forest.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7af26586-52ac-490f-8995-782aacc8e553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее R2: 0.19206271466617383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model_grad = GradientBoostingRegressor()\n",
    "\n",
    "model_grad.fit(X_train_ic, y_train_ic)\n",
    "pred_grad_ic = model_grad.predict(X_test_ic)\n",
    "scores_grad = cross_val_score(model_grad, X_train_ic, y_train_ic, cv=5, scoring='r2')\n",
    "print(\"Среднее R2:\", scores_grad.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89716e3-ede7-4655-b9e9-c0653a1ae5a6",
   "metadata": {},
   "source": [
    "Применение только алгоритмов машинного обучения даже при должной обработке и кросс-валидации дают крайне низкие результаты. В силу специфики поставленной задачи, возможно, работать со всеми химическими соединениями и биологическими классами подряд не совсем логично - они могут быть различнуми по типу соединеяни и молекулярной структуре, из-за чего работа с видами этих соединений по отдельности (применение к каждому виду алгоритмов машинного обучения) покажет лучший результат. Для решения задачи можно попробовать применить кластеризацию, и только после этого использовать алгоритмы машинного обучения, так как кластеризация способна выявить эти взаимосвязи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4b2a269b-beb9-416c-83cc-700fe1a9c5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dfu\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_ic = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans_ic.fit_predict(X_new_ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dcc68e73-e3e4-48b4-b272-dc446a058dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кластер 0: MAE=0.414, MSE=0.268, R2=0.363\n",
      "Кластер 1: MAE=0.380, MSE=0.214, R2=0.462\n",
      "Кластер 2: MAE=0.058, MSE=0.019, R2=0.946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "cluster_metrics = {}  #мы будем проходиться по каждому кластеру и к каждому из них применять выбранный алгоритм\n",
    "\n",
    "for c in np.unique(clusters):\n",
    "    X_cluster_ic = X_new_ic[clusters == c]\n",
    "    y_cluster_ic = Y_ic[clusters == c]\n",
    "    \n",
    "    model = LinearRegression().fit(X_cluster_ic, y_cluster_ic)\n",
    "    y_pred_cluster_ic = model.predict(X_cluster_ic)\n",
    "\n",
    "    mae = mean_absolute_error(y_cluster_ic, y_pred_cluster_ic)\n",
    "    mse = mean_squared_error(y_cluster_ic, y_pred_cluster_ic)\n",
    "    r2 = r2_score(y_cluster_ic, y_pred_cluster_ic)\n",
    "\n",
    "    cluster_metrics[c] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'R2': r2\n",
    "    }\n",
    "\n",
    "for cid, metrics in cluster_metrics.items():\n",
    "    print(f\"Кластер {cid}: MAE={metrics['MAE']:.3f}, MSE={metrics['MSE']:.3f}, R2={metrics['R2']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dfd242c2-a4ad-4efc-a565-4f8456433772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кластер 0: MAE=0.202, MSE=0.081, R2=0.808\n",
      "Кластер 1: MAE=0.173, MSE=0.052, R2=0.868\n",
      "Кластер 2: MAE=0.181, MSE=0.050, R2=0.859\n"
     ]
    }
   ],
   "source": [
    "cluster_metrics_forest = {}\n",
    "\n",
    "for c in np.unique(clusters):\n",
    "    X_cluster_ic = X_new_ic[clusters == c]\n",
    "    y_cluster_ic = Y_ic[clusters == c]\n",
    "    \n",
    "    model = RandomForestRegressor().fit(X_cluster_ic, y_cluster_ic)\n",
    "    y_pred_cluster_ic = model.predict(X_cluster_ic)\n",
    "\n",
    "    mae = mean_absolute_error(y_cluster_ic, y_pred_cluster_ic)\n",
    "    mse = mean_squared_error(y_cluster_ic, y_pred_cluster_ic)\n",
    "    r2 = r2_score(y_cluster_ic, y_pred_cluster_ic)\n",
    "\n",
    "    cluster_metrics_forest[c] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'R2': r2\n",
    "    }\n",
    "\n",
    "for cid, metrics in cluster_metrics_forest.items():\n",
    "    print(f\"Кластер {cid}: MAE={metrics['MAE']:.3f}, MSE={metrics['MSE']:.3f}, R2={metrics['R2']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "91a552bc-c0f4-47cb-a6aa-109ba60a7dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кластер 0: MAE=0.260, MSE=0.114, R2=0.730\n",
      "Кластер 1: MAE=0.130, MSE=0.033, R2=0.918\n",
      "Кластер 2: MAE=0.065, MSE=0.019, R2=0.946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "cluster_metrics_grad = {}\n",
    "\n",
    "for c in np.unique(clusters):\n",
    "    X_cluster_ic = X_new_ic[clusters == c]\n",
    "    y_cluster_ic = Y_ic[clusters == c]\n",
    "    \n",
    "    model = GradientBoostingRegressor().fit(X_cluster_ic, y_cluster_ic)\n",
    "    y_pred_cluster_ic = model.predict(X_cluster_ic)\n",
    "\n",
    "    mae = mean_absolute_error(y_cluster_ic, y_pred_cluster_ic)\n",
    "    mse = mean_squared_error(y_cluster_ic, y_pred_cluster_ic)\n",
    "    r2 = r2_score(y_cluster_ic, y_pred_cluster_ic)\n",
    "\n",
    "    cluster_metrics_grad[c] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'R2': r2\n",
    "    }\n",
    "\n",
    "for cid, metrics in cluster_metrics_grad.items():\n",
    "    print(f\"Кластер {cid}: MAE={metrics['MAE']:.3f}, MSE={metrics['MSE']:.3f}, R2={metrics['R2']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8113586-521c-4cc7-87a4-c86167fdc06a",
   "metadata": {},
   "source": [
    "Лучше всего на задаче регресси себя показал градиентный бустинг с использованием кластеризации. При этом мы видим, что нулевой кластер несет в себе меньше всего информации, а первый и второй более информативны, возможно, из-за того, что классы в них более информативны, а химические свойства более однородны."
   ]
  }
